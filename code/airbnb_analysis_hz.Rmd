---
title: "Airbnb price prediction - Lisbon"
author: "Fanni Kiss & Zsombor Hegedus"
date: '2021 janu√°r 31 '
output:
    prettydoc::html_pretty:
     theme: architect
     highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pack_n_load, include=FALSE}
rm(list = ls())

library(tidyverse)
library(data.table)
library(rattle)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(kableExtra)
library(xtable)
library(moments)
library(cowplot)
library(ggpubr)

#source(paste0(w_dir,'/code/helper.R'))
source('https://raw.githubusercontent.com/zsomborh/airbnb_lisbon/main/code/helper.R')

w_dir = 'C:/Users/T450s/Desktop/programming/git/airbnb_lisbon'
df <- read_csv('https://raw.githubusercontent.com/zsomborh/airbnb_lisbon/main/data/clean/cleaned_airbnb.csv')

df <- df %>% mutate(
  property_type = as.factor(property_type),
  ln_price = log(price)
)

colnames(df) <- tolower(colnames(df))
```

## Executive summary

Our goal is to help our client price the rental fee for short time use of their small and mid-size apartments in Lisbon. In order to do so we built price predictor models based on a recent date: 20th Dec, 2020 using publicly available data scraped from Airbnb on [Inside Airbnb](http://insideairbnb.com/get-the-data.html). Our features captured information about the host, the number and quality of previous guest experiences, details of the accomodation and ultimately price, which was our target variable. We built several machine learning models such as OLS, Lasso, CART, GBM but in the end a random forest model was chosen as the best out of the lot. We evaluated the models with 5-fold cross validation both on a work and holdout set with RMSE being our loss function where the random forest was superior. We believe that our model is robust and can be of great help for our client both in case they want to advertise their accomodations with separate rooms or whole apartments as well. 

*One disclaimer:* Our choice of the date was quite arbitrary and possibly not the best considering the low volume of turism in December and the ongoing COVID-19 pandemic. Nevertheless we just want to showcase what we are able to do with the data at our displosal and we are happy to rerun the analysis for the client in a more appropriate time as well.

## Airbnb data 

In order to be able to build our models we did a heavy cleaning on the data downloaded from Inside Airbnb. We were informed that the client owns real estate in the heart of Lisbon only and that they own apartments that can accomodate 2-6 people only, so we narrowed our scope accordingly. We got rid of observations that do not belong to Lisbon or were not apartments (we also included condominimums) or apartment rooms for 2-6 people. Whether a property is a full apartment or a room is going to be very important furthermore in this analysis, because we want to show the client what options they have were they to decide to rent out not only full apartments but separate rooms as well. Furthermore, we excluded observations where the price was more than EUR1000/night as those were considered to be extreme values that are either erroneous or very much outside of the client's expectation. We aimed to keep as many variables as possible and dropped missing values only in rare cases, so we used imputation when that was necessary. The cleaning steps are documented in our [github repo](https://github.com/zsomborh/airbnb_lisbon/blob/main/code/clean_airbnb.R).

Overall we included variables that could be grouped into the following categories: 

- **Base Variables**: Such were the number of bedrooms, bathrooms, accommodates, the type of property which was either apartmant or room and the minimum nights one has to stay in the accommodation.
- **Host Information**: These variables were of the host of the apartmant such as the number of years they were hosts on Airbnb, how many listed apartmants they have, whether their identity is verified or if they are superhosts.
- **Reviews**: This category aims to capture the kind of feedback the accommodation received from the guests so far - these are the number of reviews, the average rating it received from clients from 1-10 and the amount of rating they receive in a month on average. 
- **Amenities**: These capture the extras that an accomodation can offer e.g.: whether it has a kitchen, coffee machine, or has locks on the door - from modeling perspective all such tags that were used more than 100 times were converted to dummies (e.g if accommodation has shampoo tag, it will receive a 1, and 0 otherwise). We decided not to keep them all as some tags appeared very infrequently and such low variation in a predictor would just throw off the model as opposed to improving it. 

## EDA

Our target variable is price, a right skewed variable with a long right tail. On average in our sample apartmant costed almost twice as much as rooms, which is perfectly understandable given that the freedom of a whole apartment is something that people are willing to pay more. In total we have a bit more than 11k observations in which the number of apartments is almost four times more than the number of rooms. 

```{r table 1, echo = FALSE , results = "asis", warning = FALSE, message = FALSE }

price_sum <- df %>% group_by(property_type) %>% summarise(
    mean     = mean(price),
    median   = median(price),
    std      = sd(price),
    iq_range = IQR(price), 
    min      = min(price),
    max      = max(price),
    skew     = skewness(price),
    numObs   = sum( !is.na( price ) ) )

knitr::kable(price_sum, caption= 'Descriptive statistics of price for rooms and apartmants', digits = c(0,rep(2,ncol(price_sum)-2),0)) 
```

```{r fig 1, fig.width=10,fig.height=4, fig.cap='Distribution of apartment and room prices 20th Dec, 2020', echo = FALSE , results = "asis", warning = FALSE, message = FALSE }
p1 <- ggplot( data = df[df$property_type == 'apartment',] , aes( x = price ) ) +
    geom_histogram( aes(y = ..density..) , alpha = 1, binwidth = 30, color = 'black', fill = 'navyblue') +
    geom_density( aes(y = ..density..) , alpha = .5 , bw = 50, color = 'black', fill='steelblue') +
    labs(x='Price distribution of apartments',y='Density') + theme_minimal() 

p2 <- ggplot( data = df[df$property_type == 'room',] , aes( x = price ) ) +
    geom_histogram( aes(y = ..density..) , alpha = 1, binwidth = 30, color = 'black', fill = 'purple4') +
    geom_density( aes(y = ..density..) , alpha = .5 , bw = 50, color = 'black', fill='darkorchid2') +
    labs(x='Price distribution of rooms',y='Density') + theme_minimal() 

ggarrange(p1, p2, nrow = 1 )
```

We also created boxplots to further highlight the differences in price for certain categories. The number of minimum nights for example had no bearing whatsoever on the price - there is a very slight downward tendency - so if someone rented their apartment out for longer periods only, the asking price on average was slightly lower. We saw a quasi linear trend in prices in case there were more accomodates, for both rooms and apartments, which is of course within expectations. However one interesting finding looking at these plots was that there is no visible difference between price for veteran, or newer hosts, and neither was there any for higher and lower rated accommodations. It would be foolish to draw conclusions from these boxplots only, but our intuition was that better rated accomodations would be priced higher, as it seemed rational that people would be happy to pay premium to stay at a place with a good reputation. 

```{r fig 2, fig.width=10,fig.height=8, fig.cap='Boxplot of price by  minimum nights, number of accomodates, hosting history and review scores', echo = FALSE , results = "asis", warning = FALSE, message = FALSE }

plotdf <- df %>% mutate(
    host_cat = ifelse(host_since <=3, '0-3 yrs', ifelse(host_since <= 7, '4-7 yrs','7+yrs')),
    score_cat = ifelse(review_scores_rating <= 80, '0-80', 
                       ifelse(review_scores_rating <= 85, '81-85', 
                              ifelse( review_scores_rating <= 90, '86-90',
                                      ifelse(review_scores_rating <= 95, '91-95', '96-100')))),
    min_cat = ifelse(minimum_nights ==1, '1 night',
                     ifelse(minimum_nights == 2, '2 nights', 
                        ifelse(minimum_nights == 3, '3 nights', '4+ nights')))) %>% 
    select(bedrooms,property_type, accommodates, host_cat,score_cat, price, min_cat)

p1 <- ggplot(plotdf, aes(x = factor(min_cat), y = price,
                        fill = factor(property_type), color=factor(property_type))) +
    geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
    scale_color_manual( name = '', values = c('black', 'black')) +
    scale_fill_manual( name = '', values = c('navyblue', 'purple4')) +
    stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
    labs(x = "Minimum nights",y = "Price (EUR)")+
    theme_minimal() +
    theme(legend.position = c(0.15,0.8))+
    scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 250), breaks = seq(0,250, 50))

p2 <- ggplot(plotdf, aes(x = factor(accommodates), y = price,
                        fill = factor(property_type), color=factor(property_type))) +
    geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
    scale_color_manual( name = '', values = c('black', 'black')) +
    scale_fill_manual( name = '', values = c('navyblue', 'purple4')) +
    stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
    labs(x = "Accomodates (Persons)",y = "Price (EUR)")+
    theme_minimal() +
    theme(legend.position = c(0.15,0.8))+
    scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 250), breaks = seq(0,250, 50))

p3 <- ggplot(plotdf, aes(x = factor(host_cat), y = price,
                        fill = factor(property_type), color=factor(property_type))) +
    geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
    scale_color_manual( name = '', values = c('black', 'black')) +
    scale_fill_manual( name = '', values = c('navyblue', 'purple4')) +
    stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
    labs(x = "How long host is present in Airbnb",y = "Price (EUR)")+
    theme_minimal() +
    theme(legend.position = c(0.15,0.8))+
    scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 200), breaks = seq(0,200, 50))

p4 <- ggplot(plotdf, aes(x = factor(score_cat), y = price,
                        fill = factor(property_type), color=factor(property_type))) +
    geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
    scale_color_manual( name = '', values = c('black', 'black')) +
    scale_fill_manual( name = '', values = c('navyblue', 'purple4')) +
    stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
    labs(x = "Review scores",y = "Price (EUR)")+
    theme_minimal() +
    theme(legend.position = c(0.15,0.8))+
    scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 200), breaks = seq(0,200, 50))


ggarrange(p1,p2,p3,p4, nrow = 2, ncol = 2)
```

## Feature Engineering

We had 94 predictors out of which 80 were made from the amenities. When it came to amenities, functional for was not really a question as they were dummy variables. From the remainder, we mostly had discrete numeric variables with a smaller range (e.g. bedrooms were between 1 to 7) most of which were quite skewed. We decided that log transformation would not really help in most of the cases due to the limited number of possible $x$ values, but we did transform the number of minimum nights and the listings count that the host had.

We were also trying to search for possible useful interactions from the sea of variables that we had. For this we handpicked a few amenities that we thought could make a difference in someone's choosing (we have used Airbnb services before and tried to use our own experience in deciding) and also tried to pick out those that were used relatively frequently and check their interaction with the `property_type`. For visual demonstration we created 12 plots out of which we identified 4 potentially useful interactions. 

```{r fig 3, fig.width=10,fig.height=8, fig.cap='Bar plots of average prices for handpicked amenities interacting with property types', echo = FALSE , results = "asis", warning = FALSE, message = FALSE }
p1 <- price_diff_by_variables2(df, "property_type", "coffee_maker", "Property type", 'Coffee Maker')
p2 <- price_diff_by_variables2(df, "property_type", "wifi", "Property type", 'Wifi')
p3 <- price_diff_by_variables2(df, "property_type", "dishwasher", "Property type", 'Dishwasher') # looks good
p4 <- price_diff_by_variables2(df, "property_type", "elevator", "Property type", 'Elevator')
p5 <- price_diff_by_variables2(df, "property_type", "lock_on_bedroom_door", "Property type", 'Lock on bedroom')
p6 <- price_diff_by_variables2(df, "property_type", "microwave", "Property type", 'Microwave')
p7 <- price_diff_by_variables2(df, "property_type", "kitchen", "Property type", 'Kitchen') # looks good
p8 <- price_diff_by_variables2(df, "property_type", "lockbox", "Property type", 'LockBox') # looks good 
p9<- price_diff_by_variables2(df, "property_type", 'luggage_dropoff_allowed', "Property type",'Luggage dropoff')
p10<- price_diff_by_variables2(df, "property_type", 'patio_or_balcony', "Property type", 'Balcony avaialable') # looks good
p11<- price_diff_by_variables2(df, "property_type", 'refrigerator', "Property type", 'Fridge')
p12<- price_diff_by_variables2(df, "property_type", 'self_checkin', "Property type", 'Self Check-in') # looks good 

interaction_plot <- plot_grid(p1, p2, p3, p4, p5, p6, p7 ,p8, p9, p10, p11,p12, nrow=3, ncol=4)
interaction_plot
```

## Modeling

We wanted to run less complicated models first and see how they faired compared to more complex ones. Our machine learning approach started off with creating a random 25% holdout subset, and train our models on the rest. We used 5-fold cross validation as a control and a convex symmetric loss function: RMSE. The RMSE which served an important role in our final model choice was the average of the 5 RMSEs calculated after each fold. We also calculated the RMSE after predicting on the holdout set and while the differences in performance were not huge, more complex models did better.

#### OLS and Lasso

We ran our first naive model which contained the basic variables only - this would serve as our benchmark. As we included more variables we noticed a substantial improvement, but interactions and log transformations had a mild impact on the RMSEs only. 

We had high hopes for the Lasso models as we thought we have a bunch of variables from the amenities that were probably not very significant, and the $\lambda$ penalty term would drop most of them out and reduce the noise. What happened was contrary to this belief - we tuned our Lasso models to look for multiple $\lambda$s between .01 and 1 with a step of .01 - as very few of the estimated variable coefficients were reduced to zero. This way Lasso also lost it's biggest advantage and couldn't really outperform the OLS models. The below tables summarise the OLS and Lasso RMSEs both in the cross validated case and also as estimated on the holdout. 
``` {r modeling prep, include = FALSE}
# variable groupping 
target_var = 'price'

basic_vars <- c('property_type', 'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'bathrooms')

host_info <- c('host_since', 'host_is_superhost', 'host_listings_count', 'host_identity_verified')

reviews <- c('number_of_reviews', 'review_scores_rating','reviews_per_month', 'flag_review_scores_rating')

amenities <- colnames(df)[!colnames(df) %in% c('id',target_var, basic_vars, host_info,host_info,reviews)]

cont_vars <- c('minimum_nights', 'bedrooms','beds','bathrooms', 'host_since', 'host_listings_count', 'review_scores_rating', 'reviews_per_month', 'number_of_reviews')

# Get interactions 

df <- get_lns(df,cont_vars,5)
ln_vars <- colnames(df)[!colnames(df) %in% c(basic_vars,host_info,reviews,amenities,'id', 'price')]
interactions1 <- c('property_type * dishwasher',
                   'property_type * kitchen',
                   'property_type * lockbox',
                   'property_type * patio_or_balcony',
                   'property_type * self_checkin'
)

interactions2 <- c(paste0('property_type * (',paste(amenities, collapse = '+'),')'))

df <- df %>% mutate(
    ln_price = log(price),
    ln_minimum_nights =       ifelse(is.infinite(ln_minimum_nights),0,ln_minimum_nights),
    ln_host_listings_count =  ifelse(is.infinite(ln_host_listings_count),0,ln_host_listings_count),
    ln_price =                ifelse(is.infinite(ln_price),0,ln_price)
)
#create predictors sets

predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, host_info, reviews, amenities)
transformed <- substring(ln_vars,4)

predictors_transformed_small <- c(predictors_2[!predictors_2 %in% transformed],interactions1,ln_vars)
predictors_transformed_big <- c(predictors_2[!predictors_2 %in% transformed],interactions2,ln_vars)

#  create holdout set 
set.seed(7)
train_indices <- as.integer(createDataPartition(df$price, p = 0.75, list = FALSE))
df_train <- df[train_indices, ]
df_holdout <- df[-train_indices, ]
# train control is 5 fold cross validation
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)

```

```{r ols modeling, include = FALSE}

set.seed(7)
system.time({
  ols_model1 <- train(
    formula(paste0("price ~", paste0(predictors_1, collapse = " + "))),
    data = df_train,
    method = "lm",
    trControl = train_control
  )
})
set.seed(7)
system.time({
    ols_model2 <- train(
        formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
        data = df_train,
        method = "lm",
        trControl = train_control
    )
})

set.seed(7)
system.time({
    ols_model3 <- train(
        formula(paste0("price ~", paste0(predictors_transformed_small, collapse = " + "))),
        data = df_train,
        method = "lm",
        trControl = train_control
    )
})

set.seed(7)
system.time({
  lasso_model <- train(
    formula(paste0("price ~", paste0(predictors_transformed_small, collapse = " + "))),  
    data = df_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 1, by = 0.01)),
    trControl = train_control
  )
})

set.seed(7)
system.time({
    lasso_model2 <- train(
        formula(paste0("price ~", paste0(predictors_transformed_big, collapse = " + "))), 
        data = df_train,
        method = "glmnet",
        preProcess = c("center", "scale"),
        tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 1, by = 0.01)),
        trControl = train_control
    )
})


temp_models <-
    list("OLS - basic variables" = ols_model1,
         "OLS2 - all variables without transformation" = ols_model2,
         "OLS3 - variables with ln transformation and interactions" = ols_model3,
         "LASSO1 - all variables  w/ few interactions + ln transformations" = lasso_model,
         "LASSO2 - all variables  w/ all interactions + ln transformations" = lasso_model2)

result_temp <- resamples(temp_models) %>% summary()


result_rmse <- imap(temp_models, ~{
    mean(result_temp$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
    rename("CV RMSE" = ".")

result_holdout <- map(temp_models, ~{
    RMSE(predict(.x, newdata = df_holdout), df_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
    rename("Holdout RMSE" = ".")

a <- names(temp_models)
b <- result_rmse$`CV RMSE`
c <- result_holdout$`Holdout RMSE`
tf <- data.frame(a,b,c)
colnames(tf) <- c('Model', 'CV RMSE', 'Holdout RMSE')



```

```{r table 2, echo = FALSE , results = "asis", warning = FALSE, message = FALSE }

knitr::kable(tf, caption= 'Model comparison for OLS and Lasso models in CV and Holdout RMSE ', digits = c(3,3)) 
```